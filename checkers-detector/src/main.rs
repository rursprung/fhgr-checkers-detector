//! This application can detect and identify checkers pieces on a board generated by
//! the accompanying `board-generator`.

#![forbid(unsafe_code)]
#![deny(warnings)]
#![deny(missing_docs)]
#![deny(missing_debug_implementations)]
#![deny(unused)]

mod board_extractor;
mod camera_control;
mod detector;
mod util;

use crate::board_extractor::{BoardExtractorError, Config as BoardExtractorConfig, extract_board};
use crate::camera_control::Esp32Cam;
use crate::detector::{
    BoardLayout, CalibratedDetector, Config as DetectorConfig, DebugFieldConfig, Detector,
    FieldOccupancy, FieldPosition,
};
use crate::util::{field_mask_roi, resize_and_show};
use DetectorError::*;
use clap::Parser;
use lazy_static::lazy_static;
use log::{debug, info, warn};
use opencv::{
    core::{Point2i, Rect2i, Scalar, ToInputOutputArray, mean_std_dev_def},
    highgui::{MouseEventTypes, named_window_def, set_mouse_callback, wait_key, wait_key_def},
    imgcodecs::imread_def,
    imgproc::{COLOR_RGB2HSV, FONT_HERSHEY_COMPLEX, LINE_8, cvt_color_def, line, put_text_def},
    prelude::*,
    videoio::VideoCapture,
};
use std::cmp::{max, min};
use std::fmt::{Display, Formatter};
use std::sync::Mutex;
use url::Url;

/// Defines a fixed length for the edge of a field in the rectified image
const PX_PER_FIELD_EDGE: u8 = 128;

const COLOR_GREEN: Scalar = Scalar::new(0.0, 255.0, 0.0, 0.0);

#[derive(Copy, Clone, Debug, clap::ValueEnum)]
enum CameraType {
    Esp32Cam,
}

#[derive(Debug, Clone, clap::Args)]
#[group(required = true, multiple = false)]
struct InputConfig {
    /// Defines an image as input. Either this or a video feed _must_ be specified.
    #[arg(short, long)]
    image_input: Option<String>,
    /// Defines a video feed as input. Either this or a static image _must_ be specified.
    #[arg(short, long)]
    video_input: Option<String>,
}

#[derive(Debug, Clone, clap::Parser)]
struct Config {
    /// The number of fields per row & column. Defines an nâœ•n board.
    #[arg(short, long, default_value = "8")]
    num_fields_per_line: u8,
    /// Defines the input to be used.
    #[clap(flatten)]
    input: InputConfig,
    /// The type of the camera which is being accessed.
    #[arg(short, long, value_enum, requires = "video_input")]
    camera_type: Option<CameraType>,
    /// If specified, additional information about the processing of the specified field is shown.
    /// Either specify 'all' or a field position (e.g. 'A1')
    #[cfg(feature = "show_debug_screens")]
    #[arg(long)]
    debug_field: Option<String>,
}

impl Config {
    fn debug_field(&self) -> Result<DebugFieldConfig> {
        #[cfg(not(feature = "show_debug_screens"))]
        return Ok(DebugFieldConfig::None);

        #[cfg(feature = "show_debug_screens")]
        {
            use crate::detector::FieldPosition;
            let debug_field = self.debug_field.as_ref().map(|s| s.to_uppercase());
            match debug_field {
                None => Ok(DebugFieldConfig::None),
                Some(s) if s == "ALL" => Ok(DebugFieldConfig::All),
                Some(ref s) => Ok(DebugFieldConfig::Specific(FieldPosition::try_from_str(
                    &s,
                    self.num_fields_per_line,
                )?)),
            }
        }
    }

    fn num_columns_total(&self) -> u8 {
        // one for the aruco marker and one for the labels per side
        self.num_fields_per_line + 4
    }

    fn image_edge_length(&self) -> i32 {
        PX_PER_FIELD_EDGE as i32 * self.num_columns_total() as i32
    }
}

#[derive(Debug)]
enum DetectorError {
    UrlParseError(url::ParseError),
    UrlMustBeBaseUrl(String, String),
    ImageAcquisitionFailure(Option<opencv::Error>),
    OtherOpenCVError(opencv::Error),
    BoardNotFound,
    InternalDetectionError(detector::DetectorError),
}

impl Display for DetectorError {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        match self {
            UrlParseError(_) => write!(f, "Url parse error"),
            UrlMustBeBaseUrl(url, expected_base_url) => write!(
                f,
                "Camera URLs do not match! expected {} but got {}",
                expected_base_url, url
            ),
            ImageAcquisitionFailure(_) => write!(f, "image acquisition failed"),
            OtherOpenCVError(_) => write!(f, "Generic OpenCV Error"),
            BoardNotFound => write!(
                f,
                "Board not found in image. Are all aruco markers in view?"
            ),
            InternalDetectionError(_) => write!(f, "internal detection error"),
        }
    }
}

impl std::error::Error for DetectorError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match self {
            UrlParseError(e) => Some(e),
            ImageAcquisitionFailure(Some(e)) => Some(e),
            OtherOpenCVError(e) => Some(e),
            InternalDetectionError(e) => Some(e),
            _ => None,
        }
    }
}

impl From<url::ParseError> for DetectorError {
    fn from(e: url::ParseError) -> Self {
        UrlParseError(e)
    }
}

impl From<BoardExtractorError> for DetectorError {
    fn from(e: BoardExtractorError) -> Self {
        use crate::board_extractor::BoardExtractorError::*;
        match e {
            OpenCVError(e) => OtherOpenCVError(e),
        }
    }
}

impl From<detector::DetectorError> for DetectorError {
    fn from(e: detector::DetectorError) -> Self {
        use detector::DetectorError::*;
        match e {
            OpenCVError(e) => OtherOpenCVError(e),
            e => InternalDetectionError(e),
        }
    }
}

/// Default to [`OtherOpenCVError`] unless `map_err` is used explicitly.
impl From<opencv::Error> for DetectorError {
    fn from(e: opencv::Error) -> Self {
        OtherOpenCVError(e)
    }
}

type Result<T> = std::result::Result<T, DetectorError>;

lazy_static! {
    static ref VIEWER: Mutex<BoardViewer> = Mutex::new(BoardViewer::new().unwrap());
}

struct BoardViewer {
    num_fields_per_line: Option<u8>,
    detector: Option<CalibratedDetector>,
    original_image: Option<Mat>,
    board: Option<Mat>,
    result: Option<BoardLayout>,
}

impl BoardViewer {
    fn new() -> Result<Self> {
        named_window_def("board")?;
        set_mouse_callback("board", Some(Box::new(Self::handle_mouse_cb)))?;
        Ok(Self {
            num_fields_per_line: None,
            detector: None,
            original_image: None,
            board: None,
            result: None,
        })
    }

    fn init(&mut self, detector: CalibratedDetector, num_fields_per_line: u8) {
        self.detector = Some(detector);
        self.num_fields_per_line = Some(num_fields_per_line);
    }

    fn handle_mouse_cb(event: i32, x: i32, y: i32, flags: i32) {
        VIEWER.lock().unwrap().handle_mouse(event, x, y, flags);
    }

    fn handle_mouse(&self, event: i32, x: i32, y: i32, _flags: i32) {
        let pos = FieldPosition::try_from_px(
            2 * x as u32,
            2 * y as u32,
            PX_PER_FIELD_EDGE,
            self.num_fields_per_line.unwrap(),
        )
        .unwrap();
        if event == MouseEventTypes::EVENT_LBUTTONDOWN as i32 {
            if let Some(result) = &self.result {
                if pos.is_on_board() {
                    info!("Selected field {}: {}", pos, result.get(&pos).unwrap());
                }
            }
        }
        #[cfg(feature = "show_debug_screens")]
        if event == MouseEventTypes::EVENT_RBUTTONDOWN as i32 {
            let (mean, std_dev) = self.get_mean_hsv_at_pos(&pos).unwrap();
            info!(
                "Mean HSV at field {}: mean = {:?}, std_dev = {:?}",
                pos, mean, std_dev
            );
        }
        #[cfg(feature = "show_debug_screens")]
        if event == MouseEventTypes::EVENT_MBUTTONDOWN as i32 {
            let (mean, std_dev) = self.get_mean_hsv_at_coord(x, y).unwrap();
            info!(
                "Mean HSV at [{},{}] (in field {}): mean = {:?}, std_dev = {:?}",
                x, y, pos, mean, std_dev
            );
        }
    }

    fn get_mean_std_dev_hsv_in_roi(&self, roi: Rect2i) -> Result<(Scalar, Scalar)> {
        let mut board_hsv = Mat::default();
        cvt_color_def(self.board.as_ref().unwrap(), &mut board_hsv, COLOR_RGB2HSV)?;

        let mut mean = Scalar::default();
        let mut std_dev = Scalar::default();
        mean_std_dev_def(&board_hsv.roi(roi)?, &mut mean, &mut std_dev)?;
        Ok((mean, std_dev))
    }

    fn get_mean_hsv_at_coord(&self, x: i32, y: i32) -> Result<(Scalar, Scalar)> {
        let board_width = self.board.as_ref().unwrap().rows();
        let roi_half_width_px = 20;
        let roi = Rect2i::new(
            max(x - roi_half_width_px, 0),
            max(y - roi_half_width_px, 0),
            min(x + roi_half_width_px, board_width),
            min(y + roi_half_width_px, board_width),
        );
        self.get_mean_std_dev_hsv_in_roi(roi)
    }

    fn get_mean_hsv_at_pos(&self, pos: &FieldPosition) -> Result<(Scalar, Scalar)> {
        let roi = field_mask_roi(pos, PX_PER_FIELD_EDGE);
        self.get_mean_std_dev_hsv_in_roi(roi)
    }

    /// Handle an individual frame.
    fn handle_frame(&mut self, frame: Mat, config: &Config) -> Result<()> {
        let board = extract_board(
            &frame,
            &BoardExtractorConfig {
                num_fields_per_line: config.num_fields_per_line,
                px_per_field_edge: PX_PER_FIELD_EDGE,
            },
        )?;
        if board.is_none() {
            warn!("failed to find board! skipping frame");
            return Err(BoardNotFound);
        }
        let board = board.unwrap();
        self.original_image = Some(frame);

        let result = self.detector.as_ref().unwrap().detect_pieces(&board)?;

        let mut board_annotated = Mat::default();
        board.copy_to(&mut board_annotated)?;
        annotate_image(&mut board_annotated, &result, config)?;

        resize_and_show("board", &board_annotated)?;

        debug!("{}", result);

        self.board = Some(board);
        self.result = Some(result);

        Ok(())
    }
}

/// Tries to open the specified video input and stream it while it lasts.
fn handle_video_input(config: &Config) -> Result<()> {
    let video_input = config.input.video_input.as_ref().unwrap();

    let video_input = match config.camera_type {
        Some(CameraType::Esp32Cam) => {
            let url = Url::parse(video_input).unwrap();
            let base_url = Url::parse(format!("http://{}", url.host().unwrap()).as_str()).unwrap();
            if url != base_url {
                return Err(UrlMustBeBaseUrl(url.to_string(), base_url.to_string()));
            }

            Esp32Cam::init(&base_url);

            let stream_url = format!("http://{}:81/stream", base_url.host().unwrap());
            stream_url
        }
        _ => video_input.to_string(),
    };

    let mut capture = match video_input.parse::<i32>() {
        Ok(i) => {
            debug!("opening ID based video capture {}", i);
            VideoCapture::new_def(i)
        }
        Err(_) => {
            debug!("opening path or URL based video capture {}", video_input);
            VideoCapture::from_file_def(&video_input)
        }
    }
    .map_err(|e| ImageAcquisitionFailure(Some(e)))?;
    if !capture
        .is_opened()
        .map_err(|e| ImageAcquisitionFailure(Some(e)))?
    {
        return Err(ImageAcquisitionFailure(None));
    }

    loop {
        let mut image = Mat::default();
        capture
            .read(&mut image)
            .map_err(|e| ImageAcquisitionFailure(Some(e)))?;

        match VIEWER.lock().unwrap().handle_frame(image, config) {
            Ok(_) | Err(BoardNotFound) => {}
            Err(e) => return Err(e),
        }

        let key = wait_key(1)?;
        if key == 'q' as i32 {
            return Ok(());
        }
    }
}

fn overlay_grid<M>(image: &mut M, config: &Config) -> Result<()>
where
    M: MatTrait + opencv::core::ToInputOutputArray,
{
    for i in 1..config.num_columns_total() as i32 {
        // horizontal line
        line(
            image,
            Point2i::new(0, i * PX_PER_FIELD_EDGE as i32),
            Point2i::new(config.image_edge_length(), i * PX_PER_FIELD_EDGE as i32),
            COLOR_GREEN,
            3,
            LINE_8,
            0,
        )?;
        // vertical line
        line(
            image,
            Point2i::new(i * PX_PER_FIELD_EDGE as i32, 0),
            Point2i::new(i * PX_PER_FIELD_EDGE as i32, config.image_edge_length()),
            COLOR_GREEN,
            3,
            LINE_8,
            0,
        )?;
    }

    Ok(())
}

fn annotate_image<M>(image: &mut M, layout: &BoardLayout, config: &Config) -> Result<()>
where
    M: MatTrait + ToInputOutputArray,
{
    overlay_grid(image, config)?;

    for (pos, field) in layout.field_iter() {
        if let FieldOccupancy::Occupied(_, _) = field {
            let text = format!("{}", field);
            let pos = Point2i::new(
                PX_PER_FIELD_EDGE as i32 * pos.col_in_img() as i32 + 10,
                PX_PER_FIELD_EDGE as i32 * (pos.row_in_img() as i32 + 1) - 10,
            );
            put_text_def(
                image,
                text.as_str(),
                pos,
                FONT_HERSHEY_COMPLEX,
                3.0,
                COLOR_GREEN,
            )?;
        }
    }

    Ok(())
}

fn main() -> Result<()> {
    env_logger::init();

    let config = Config::parse();

    let detector = Detector::new(DetectorConfig {
        num_fields_per_line: config.num_fields_per_line,
        px_per_field_edge: PX_PER_FIELD_EDGE,
        debug_field_config: config.debug_field()?,
    });
    let detector = detector.calibrate();
    VIEWER
        .lock()
        .unwrap()
        .init(detector, config.num_fields_per_line);

    if let Some(ref image_input) = config.input.image_input {
        let image = imread_def(image_input).map_err(|e| ImageAcquisitionFailure(Some(e)))?;
        {
            VIEWER.lock().unwrap().handle_frame(image, &config)?;
        }
        wait_key_def()?;
    } else if config.input.video_input.is_some() {
        handle_video_input(&config)?;
    } else {
        unreachable!("clap must ensure that either image_input or video_input is set!");
    }

    Ok(())
}
